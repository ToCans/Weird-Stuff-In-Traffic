{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "864d8f83",
   "metadata": {},
   "source": [
    "### Yolov11 Training Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1e2f1d-5f6c-4711-9277-36d23c31ba79",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a79b03-8ce8-48bf-8cb0-2b140aaff527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0.dev20250127+rocm6.3\n",
      "0.22.0.dev20250128+rocm6.3\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import re\n",
    "import cv2\n",
    "import random\n",
    "import shutil\n",
    "import torch\n",
    "import warnings\n",
    "import torchvision\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b64051c",
   "metadata": {},
   "source": [
    "##### Package Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1728d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"Torchvision version:\", torchvision.__version__)\n",
    "print(\"Is torch available?\",torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1338bd3",
   "metadata": {},
   "source": [
    "### Disable Warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a30071-ccfa-478c-9dc9-75687d0c622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61761e99-7063-4248-995f-3cb194ef0053",
   "metadata": {},
   "source": [
    "### Setting Training Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6238489d-895d-4420-9e2a-7773740b0026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Printing Necessary CUDA Info\n",
    "if str(device) == \"cuda\":\n",
    "    print(f\"Using GPU {torch.cuda.get_device_properties(device)}\")\n",
    "    print(\"# of CUDA devices available:\", torch.cuda.device_count())\n",
    "else:\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3ce8d6-12a0-468f-873c-e7aec1f8ca2d",
   "metadata": {},
   "source": [
    "### Emptying the GPU Cache (if necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904136e3-472c-4e2f-9ed5-cb2e67036b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning out the device cache\n",
    "def empty_cache() -> None:\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Displaying the free memory\n",
    "def print_free_memory():\n",
    "    free, total = torch.cuda.mem_get_info(device)\n",
    "    print(f\"Percent of free memory: {round(free/total *100,2)}\")\n",
    "\n",
    "# Running GPU info related functions\n",
    "empty_cache()\n",
    "print_free_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8cb24f-246b-4477-ab75-e0064547813b",
   "metadata": {},
   "source": [
    "### Memory Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9286844f-e298-456a-ad8f-01e36e1a1d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory Summary Function\n",
    "def memory_summary() -> None:\n",
    "    print(torch.cuda.memory_summary())\n",
    "\n",
    "# Running memory summary funciton\n",
    "memory_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29286d1-e71c-4d33-805f-9ed13c9aee04",
   "metadata": {},
   "source": [
    "### Preparing GPU (if necessary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c87272-2af4-4a5f-bc22-14007272497a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For AMD GPU - 7800xt\n",
    "device_name = torch.cuda.get_device_name(0)\n",
    "if \"AMD\" in device_name or \"Radeon\" in device_name:\n",
    "    os.environ[\"HSA_OVERRIDE_GFX_VERSION\"] = \"11.0.0\"\n",
    "\n",
    "print(f\"GPU {torch.cuda.get_device_properties(device).name} is now setup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6b8164-bbd1-4810-882f-807accd0278b",
   "metadata": {},
   "source": [
    "#### Google Colab Initialization -> Later delete once running on THI servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9349cb-d82a-4b03-af61-d494ce540cb8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ff9349cb-d82a-4b03-af61-d494ce540cb8",
    "outputId": "a2b84bd3-3d4f-485f-c2a7-56688d94ec60"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mshutil\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[1;32m     10\u001b[0m zip_name\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2.5k_background.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "# Additional Package Installations\n",
    "from google.colab import drive\n",
    "!pip install ultralytics\n",
    "\n",
    "# Image Zip Directory\n",
    "zip_name= \"2.5k_background.zip\"\n",
    "\n",
    "# Mounting Google Drive and setting paths\n",
    "drive.mount('/content/drive', force_remount=True)\n",
    "zip_path = f\"/content/drive/MyDrive/Valomalo/{zip_name}\"\n",
    "unzip_path = \"/content\"\n",
    "shutil.unpack_archive(zip_path, unzip_path)\n",
    "\n",
    "# Directory Paths\n",
    "dataset_path = f'/content/{zip_name.replace(\".zip\", \"\")}/data.yaml'\n",
    "save_dir = '/content/drive/My Drive/Valomalo'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8921cbf-9358-406c-992f-76262dc7b413",
   "metadata": {},
   "source": [
    "##### Local Setting Paths for Data, Base Model, and Output Directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9676daf4-f4f2-48ad-bf77-b3d4c76d39ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old Static Dataset Paths -> Can't use on THI server\n",
    "#dataset_path = r\"C:\\Users\\Adminero\\Documents\\Valomalo\\final dataset_nobackground\\cutouts1024\\data.yaml\" #.yaml file path\n",
    "#save_dir = r\"C:\\Users\\Adminero\\Documents\\Valomalo\\Saved Runs\"\n",
    "\n",
    "# Directory Paths\n",
    "inference_dataset_name = \"coco8\" # Change this once we have the necessary data\n",
    "\n",
    "# Flexible Data Paths (needed for THI server)\n",
    "current_directory = os.getcwd()\n",
    "path_to_base_directory = re.search(rf\"(.*?){\"Weird-Stuff-In-Traffic\"}\", current_directory).group(1)\n",
    "inference_yaml_data_path = f\"Weird-Stuff-In-Traffic/Data/yolo/{inference_dataset_name}/coco8.yaml\" # Change this once we have the necessary data\n",
    "complete_inference_data_path = path_to_base_directory + inference_yaml_data_path\n",
    "\n",
    "# Model Paths\n",
    "model_name = \"yolo11n.pt\"\n",
    "simple_model_name = model_name.split(\".\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ead4800-4ba7-4b8a-8634-640d7ec273c1",
   "metadata": {},
   "source": [
    "##### Training - Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa901b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d409887e",
   "metadata": {},
   "source": [
    "##### Training - Training Configuration and Output Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75017570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training Configurations\n",
    "image_size = 620\n",
    "batch_size = 64\n",
    "\n",
    "# Output Folder Name\n",
    "output_folder_name = f'{datetime.now().strftime(\"%Y-%m-%d_%H-%M\")}_{simple_model_name}_{training_dataset_name}_{image_size}cuts_{epochs}epoch'\n",
    "\n",
    "# Results Path\n",
    "training_results_path = f\"Weird-Stuff-In-Traffic/Results/Segmentation-Detection/yolo/\"\n",
    "complete_training_results_path = path_to_base_directory + training_results_path + output_folder_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ddab2a-9efd-4ce3-b87e-3e11b8b62bca",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Cnq-eJMHG5RQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cnq-eJMHG5RQ",
    "outputId": "a556856d-9167-4a57-f33c-2133a86f23a4"
   },
   "outputs": [],
   "source": [
    "model_path = f'{zip_path.replace(\".zip\", \"\")}_v9n/weights/best.pt'\n",
    "model = YOLO(model_path)\n",
    "\n",
    "video_path = \"prediction_test.mp4\"\n",
    "\n",
    "# Directory to save the annotated video\n",
    "save_dir = '/content/drive/My Drive/Valomalo/'\n",
    "experiment = \"video_inference_v9\"\n",
    "# Run inference on the video with stream=True (to avoid memory crashes)\n",
    "results = model.predict(source=video_path,\n",
    "                        stream=True,\n",
    "                        imgsz= 640,\n",
    "                        conf=0.4,\n",
    "                        max_det=9,\n",
    "                        show_labels = False,\n",
    "                        show_conf = False,\n",
    "                        save=True,\n",
    "                        project=save_dir,\n",
    "                        name=experiment)\n",
    "\n",
    "# Process the results\n",
    "for r in results:\n",
    "    boxes = r.boxes  # Boxes object for bbox outputs\n",
    "    masks = r.masks  # Masks object for segment masks outputs\n",
    "    probs = r.probs  # Class probabilities for classification outputs\n",
    "\n",
    "print(f\"Annotated video saved to {save_dir}/{experiment}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eq1Nx6KmdN9F",
   "metadata": {
    "id": "eq1Nx6KmdN9F"
   },
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe828c4-55c0-4775-93fe-9ac1cf8e0084",
   "metadata": {},
   "source": [
    "## Builtin ray tune (Hyperband)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qcH8EVb0dNil",
   "metadata": {
    "id": "qcH8EVb0dNil"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-04-21 17:59:31</td></tr>\n",
       "<tr><td>Running for: </td><td>00:01:28.49        </td></tr>\n",
       "<tr><td>Memory:      </td><td>46.4/47.1 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 2.000: None<br>Logical resource usage: 24.0/24 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  : ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
       "  \n",
       "  \n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">     bgr</th><th style=\"text-align: right;\">      box</th><th style=\"text-align: right;\">     cls</th><th style=\"text-align: right;\">  copy_paste</th><th style=\"text-align: right;\">  degrees</th><th style=\"text-align: right;\">  fliplr</th><th style=\"text-align: right;\">   flipud</th><th style=\"text-align: right;\">    hsv_h</th><th style=\"text-align: right;\">   hsv_s</th><th style=\"text-align: right;\">   hsv_v</th><th style=\"text-align: right;\">      lr0</th><th style=\"text-align: right;\">     lrf</th><th style=\"text-align: right;\">   mixup</th><th style=\"text-align: right;\">  momentum</th><th style=\"text-align: right;\">  mosaic</th><th style=\"text-align: right;\">  perspective</th><th style=\"text-align: right;\">   scale</th><th style=\"text-align: right;\">  shear</th><th style=\"text-align: right;\">  translate</th><th style=\"text-align: right;\">  warmup_epochs</th><th style=\"text-align: right;\">  warmup_momentum</th><th style=\"text-align: right;\">  weight_decay</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>_tune_682f6_00000</td><td>RUNNING </td><td>127.0.0.1:26916</td><td style=\"text-align: right;\">0.807998</td><td style=\"text-align: right;\">0.0590594</td><td style=\"text-align: right;\">2.75534 </td><td style=\"text-align: right;\">    0.839546</td><td style=\"text-align: right;\">  10.8361</td><td style=\"text-align: right;\">0.309897</td><td style=\"text-align: right;\">0.0209788</td><td style=\"text-align: right;\">0.0686011</td><td style=\"text-align: right;\">0.146443</td><td style=\"text-align: right;\">0.845052</td><td style=\"text-align: right;\">0.086305 </td><td style=\"text-align: right;\">0.535429</td><td style=\"text-align: right;\">0.115195</td><td style=\"text-align: right;\">  0.603867</td><td style=\"text-align: right;\">0.285679</td><td style=\"text-align: right;\">  0.000450814</td><td style=\"text-align: right;\">0.469152</td><td style=\"text-align: right;\">5.92209</td><td style=\"text-align: right;\">   0.698329</td><td style=\"text-align: right;\">       0.370264</td><td style=\"text-align: right;\">        0.668647 </td><td style=\"text-align: right;\">   0.000527649</td></tr>\n",
       "<tr><td>_tune_682f6_00001</td><td>RUNNING </td><td>127.0.0.1:27636</td><td style=\"text-align: right;\">0.548319</td><td style=\"text-align: right;\">0.0974355</td><td style=\"text-align: right;\">0.449079</td><td style=\"text-align: right;\">    0.813496</td><td style=\"text-align: right;\">  35.1314</td><td style=\"text-align: right;\">0.589772</td><td style=\"text-align: right;\">0.893483 </td><td style=\"text-align: right;\">0.063297 </td><td style=\"text-align: right;\">0.76401 </td><td style=\"text-align: right;\">0.348532</td><td style=\"text-align: right;\">0.0163547</td><td style=\"text-align: right;\">0.812503</td><td style=\"text-align: right;\">0.448122</td><td style=\"text-align: right;\">  0.736004</td><td style=\"text-align: right;\">0.550122</td><td style=\"text-align: right;\">  0.000480043</td><td style=\"text-align: right;\">0.061851</td><td style=\"text-align: right;\">2.89273</td><td style=\"text-align: right;\">   0.514574</td><td style=\"text-align: right;\">       0.741771</td><td style=\"text-align: right;\">        0.0959942</td><td style=\"text-align: right;\">   0.000782802</td></tr>\n",
       "<tr><td>_tune_682f6_00002</td><td>RUNNING </td><td>127.0.0.1:27132</td><td style=\"text-align: right;\">0.495834</td><td style=\"text-align: right;\">0.0381565</td><td style=\"text-align: right;\">3.39269 </td><td style=\"text-align: right;\">    0.522161</td><td style=\"text-align: right;\">  23.5552</td><td style=\"text-align: right;\">0.680139</td><td style=\"text-align: right;\">0.136561 </td><td style=\"text-align: right;\">0.0835087</td><td style=\"text-align: right;\">0.41526 </td><td style=\"text-align: right;\">0.603452</td><td style=\"text-align: right;\">0.0556526</td><td style=\"text-align: right;\">0.670238</td><td style=\"text-align: right;\">0.294094</td><td style=\"text-align: right;\">  0.674271</td><td style=\"text-align: right;\">0.58838 </td><td style=\"text-align: right;\">  0.000239809</td><td style=\"text-align: right;\">0.797217</td><td style=\"text-align: right;\">9.50009</td><td style=\"text-align: right;\">   0.181095</td><td style=\"text-align: right;\">       2.43964 </td><td style=\"text-align: right;\">        0.0498073</td><td style=\"text-align: right;\">   0.000635946</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_tune pid=26916)\u001b[0m New https://pypi.org/project/ultralytics/8.3.112 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "\u001b[36m(_tune pid=26916)\u001b[0m Ultralytics 8.3.111 ðŸš€ Python-3.12.10 torch-2.6.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4070 SUPER, 12282MiB)\n",
      "\u001b[36m(_tune pid=26916)\u001b[0m \u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=C:\\Users\\Adminero\\Documents\\Valomalo\\final dataset_nobackground\\cutouts1024\\data.yaml, epochs=2, time=None, patience=100, batch=24, imgsz=1024, save=True, save_period=-1, cache=False, device=cuda:0, workers=8, project=C:\\Users\\Adminero\\Documents\\Valomalo\\Saved Runs, name=train14, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.0863049779114844, lrf=0.5354291282339889, momentum=0.6038670880887619, weight_decay=0.0005276491786742285, warmup_epochs=0.37026370736000236, warmup_momentum=0.6686474218983107, warmup_bias_lr=0.1, box=0.05905939322810157, cls=2.755336571812989, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.06860105158873829, hsv_s=0.1464425815693808, hsv_v=0.845051754937401, degrees=10.83606978582979, translate=0.6983290139797507, scale=0.46915198452178897, shear=5.922093048681276, perspective=0.0004508142143830468, flipud=0.020978808172154806, fliplr=0.30989691449366497, bgr=0.807997912340066, mosaic=0.2856790704856571, mixup=0.1151949953304856, copy_paste=0.8395459782129402, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=C:\\Users\\Adminero\\Documents\\Valomalo\\Saved Runs\\train14\n",
      "\u001b[36m(_tune pid=26916)\u001b[0m Overriding model.yaml nc=80 with nc=2\n",
      "\u001b[36m(_tune pid=26916)\u001b[0m \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m                    from  n    params  module                                       arguments                     \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m   0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m   1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m   2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m   3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m   4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m   5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m   6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m   7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m   8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m   9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m  10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m  11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m  12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m  13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m  14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m  15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m  16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m  17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m  18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m  19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m  20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m  21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m  22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m  23        [16, 19, 22]  1    431062  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
      "\u001b[36m(_tune pid=27636)\u001b[0m New https://pypi.org/project/ultralytics/8.3.112 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(_tune pid=27636)\u001b[0m Ultralytics 8.3.111 ðŸš€ Python-3.12.10 torch-2.6.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4070 SUPER, 12282MiB)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_tune pid=27636)\u001b[0m \u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=C:\\Users\\Adminero\\Documents\\Valomalo\\final dataset_nobackground\\cutouts1024\\data.yaml, epochs=2, time=None, patience=100, batch=24, imgsz=1024, save=True, save_period=-1, cache=False, device=cuda:0, workers=8, project=C:\\Users\\Adminero\\Documents\\Valomalo\\Saved Runs, name=train13, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.016354728253908123, lrf=0.8125030881519932, momentum=0.7360041068128451, weight_decay=0.0007828015959548872, warmup_epochs=0.7417712491280043, warmup_momentum=0.09599422311649486, warmup_bias_lr=0.1, box=0.09743548757090052, cls=0.4490786386453679, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.0632970079441245, hsv_s=0.7640102450197103, hsv_v=0.3485320607537194, degrees=35.13138749264468, translate=0.5145741097303617, scale=0.06185097013770369, shear=2.892730120150059, perspective=0.00048004270278436756, flipud=0.8934826214385398, fliplr=0.5897721849540926, bgr=0.5483192794648384, mosaic=0.5501217402686963, mixup=0.4481224083319094, copy_paste=0.8134964089810688, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=C:\\Users\\Adminero\\Documents\\Valomalo\\Saved Runs\\train13\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_tune pid=27132)\u001b[0m \n",
      "\u001b[36m(_tune pid=27132)\u001b[0m  10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      "\u001b[36m(_tune pid=27636)\u001b[0m \n",
      "\u001b[36m(_tune pid=27636)\u001b[0m  10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m YOLO11n summary: 181 layers, 2,590,230 parameters, 2,590,214 gradients, 6.4 GFLOPs\n",
      "\u001b[36m(_tune pid=26916)\u001b[0m \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m Transferred 448/499 items from pretrained weights\n",
      "\u001b[36m(_tune pid=27132)\u001b[0m \n",
      "\u001b[36m(_tune pid=27636)\u001b[0m \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[36m(_tune pid=26916)\u001b[0m \u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[36m(_tune pid=26916)\u001b[0m Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0.00/5.35M [00:00<?, ?B/s]\n",
      "  7%|â–‹         | 384k/5.35M [00:00<00:01, 3.10MB/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.35M/5.35M [00:01<00:00, 5.14MB/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.35M/5.35M [00:01<00:00, 4.95MB/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.35M/5.35M [00:01<00:00, 3.18MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_tune pid=26916)\u001b[0m \u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Adminero\\Documents\\Valomalo\\final dataset_nobackground\\cutouts1024\\train\\labels.cache... 2471 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2471/2471 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_tune pid=26916)\u001b[0m \u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 385.3Â±55.1 MB/s, size: 173.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0.00/5.35M [00:00<?, ?B/s]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4.50M/5.35M [00:01<00:00, 4.48MB/s]\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Adminero\\Documents\\Valomalo\\final dataset_nobackground\\cutouts1024\\val\\labels.cache... 308 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 308/308 [00:00<?, ?it/s]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_tune pid=27636)\u001b[0m Overriding model.yaml nc=80 with nc=2\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_tune pid=27636)\u001b[0m                    from  n    params  module                                       arguments                     \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_tune pid=27636)\u001b[0m  20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[36m(_tune pid=27636)\u001b[0m   4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_tune pid=27636)\u001b[0m  22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_tune pid=27636)\u001b[0m   9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_tune pid=27636)\u001b[0m  14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_tune pid=27636)\u001b[0m  21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_tune pid=27636)\u001b[0m  19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_tune pid=27636)\u001b[0m  23        [16, 19, 22]  1    431062  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_tune pid=27636)\u001b[0m YOLO11n summary: 181 layers, 2,590,230 parameters, 2,590,214 gradients, 6.4 GFLOPs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_tune pid=27636)\u001b[0m Transferred 448/499 items from pretrained weights\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_tune pid=27636)\u001b[0m Freezing layer 'model.23.dfl.conv.weight'\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_tune pid=27636)\u001b[0m \u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_tune pid=27636)\u001b[0m Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_tune pid=27636)\u001b[0m \u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_tune pid=26916)\u001b[0m \u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1212.9Â±378.7 MB/s, size: 177.3 KB)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_tune pid=26916)\u001b[0m Plotting labels to C:\\Users\\Adminero\\Documents\\Valomalo\\Saved Runs\\train14\\labels.jpg... \n",
      "\u001b[36m(_tune pid=27636)\u001b[0m \u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 317.2Â±97.7 MB/s, size: 177.3 KB)\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 17:59:31,882\tWARNING tune.py:219 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2025-04-21 17:59:31,886\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to 'C:/Users/Adminero/Documents/Valomalo/Saved Runs/tune_exp_18' in 0.0033s.\n",
      "  0%|          | 0/103 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Adminero\\Documents\\Valomalo\\final dataset_nobackground\\cutouts1024\\val\\labels.cache... 308 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 308/308 [00:00<?, ?it/s]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_tune pid=27636)\u001b[0m \u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.016354728253908123' and 'momentum=0.7360041068128451' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[36m(_tune pid=27636)\u001b[0m \u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0008806517954492481), 87 bias(decay=0.0)\n",
      "\u001b[36m(_tune pid=27636)\u001b[0m Image sizes 1024 train, 1024 val\n",
      "\u001b[36m(_tune pid=27636)\u001b[0m Using 8 dataloader workers\n",
      "\u001b[36m(_tune pid=27636)\u001b[0m Logging results to \u001b[1mC:\\Users\\Adminero\\Documents\\Valomalo\\Saved Runs\\train13\u001b[0m\n",
      "\u001b[36m(_tune pid=27636)\u001b[0m Starting training for 2 epochs...\n",
      "\u001b[36m(_tune pid=27636)\u001b[0m \n",
      "\u001b[36m(_tune pid=27636)\u001b[0m       Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[36m(_tune pid=27132)\u001b[0m Plotting labels to C:\\Users\\Adminero\\Documents\\Valomalo\\Saved Runs\\train14\\labels.jpg... \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_tune pid=27132)\u001b[0m \n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "from ray import tune\n",
    "\n",
    "model_name = \"yolo11n.pt\"\n",
    "model = YOLO(model_name)\n",
    "hypp_space = {}\n",
    "\n",
    "result_grid = model.tune(\n",
    "    device='cuda:0',\n",
    "    data=dataset_path,\n",
    "    iterations=3,\n",
    "    grace_period = 2,\n",
    "    name=\"tune_exp_1\", \n",
    "    #space = hypp_space,\n",
    "    #resume=True,\n",
    "    imgsz=1024,\n",
    "    epochs=2,\n",
    "    batch=24,\n",
    "    project=save_dir,\n",
    "    use_ray=True)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
