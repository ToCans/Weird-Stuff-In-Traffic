{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import warnings\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disabling Warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting Training Device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU _CudaDeviceProperties(name='AMD Radeon RX 7800 XT', major=11, minor=0, gcnArchName='gfx1100', total_memory=16368MB, multi_processor_count=30, uuid=38336232-6265-3432-3662-306564613532, L2_cache_size=4MB)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if str(device) == \"cuda\":\n",
    "    print(f\"Using GPU {torch.cuda.get_device_properties(device)}\")\n",
    "else:\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emptying the GPU Cache (if necessary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of free memory: 94.13\n"
     ]
    }
   ],
   "source": [
    "def empty_cache() -> None:\n",
    "    # Cleaning out the device cache\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "def print_free_memory() -> None:\n",
    "    free, total = torch.cuda.mem_get_info(device)\n",
    "    print(f\"Percent of free memory: {round(free/total *100,2)}\")\n",
    "\n",
    "\n",
    "empty_cache()\n",
    "print_free_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memory Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def memory_summary() -> None:\n",
    "    print(torch.cuda.memory_summary())\n",
    "\n",
    "\n",
    "memory_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing GPU (if necessary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU AMD Radeon RX 7800 XT is now setup\n"
     ]
    }
   ],
   "source": [
    "# For AMD GPU - 7800xt\n",
    "device_name = torch.cuda.get_device_name(0)\n",
    "if \"AMD\" in device_name or \"Radeon\" in device_name:\n",
    "    os.environ[\"HSA_OVERRIDE_GFX_VERSION\"] = \"11.0.0\"\n",
    "\n",
    "print(f\"GPU {torch.cuda.get_device_properties(device).name} is now setup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting Paths for Data, Base Model, and Output Directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory Paths\n",
    "training_dataset_name, validation_dataset_name, data_method = \"coco8\", \"validation_dataset\", \"clean\"\n",
    "current_directory = os.getcwd()\n",
    "path_to_base_directory = re.search(rf\"(.*?){\"Weird-Stuff-In-Traffic\"}\", current_directory).group(1)\n",
    "validation_yaml_data_path = f\"Weird-Stuff-In-Traffic/Data/yolo/{training_dataset_name}/coco8.yaml\"\n",
    "complete_validation_data_path = path_to_base_directory + validation_yaml_data_path\n",
    "\n",
    "# Training Configuration used for validation results path\n",
    "model_training_config = f\"{training_dataset_name}_{data_method}\"\n",
    "\n",
    "# Model Paths\n",
    "pretrained_model_path = f\"Weird-Stuff-In-Traffic/Models/Segmentation-Detection/yolo/{training_dataset_name}_{data_method}/experiment\"\n",
    "full_pretrained_model_path = path_to_base_directory + pretrained_model_path + \"/weights/best.pt\"\n",
    "\n",
    "# Results Path\n",
    "validation_results_path = f\"Weird-Stuff-In-Traffic/Results/Segmentation-Detection/yolo/\"\n",
    "complete_validation_results_path = path_to_base_directory + validation_results_path + model_training_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Pretrained Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(full_pretrained_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.103 ðŸš€ Python-3.12.3 torch-2.7.0.dev20250127+rocm6.3 CUDA:0 (AMD Radeon RX 7800 XT, 16368MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,616,248 parameters, 0 gradients, 6.5 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/tom/Desktop/Programming/Shared/Weird-Stuff-In-Traffic/Data/yolo/coco8/labels/val.cache... 4 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  5.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         17      0.565       0.85      0.849      0.632\n",
      "                person          3         10      0.549        0.6      0.595      0.276\n",
      "                   dog          1          1      0.543          1      0.995      0.697\n",
      "                 horse          1          2      0.528          1      0.995      0.674\n",
      "              elephant          1          2      0.365        0.5      0.519      0.257\n",
      "              umbrella          1          1      0.564          1      0.995      0.995\n",
      "          potted plant          1          1       0.84          1      0.995      0.895\n",
      "Speed: 0.1ms preprocess, 4.4ms inference, 0.0ms loss, 24.1ms postprocess per image\n",
      "Saving /home/tom/Desktop/Programming/Shared/Weird-Stuff-In-Traffic/Results/Segmentation-Detection/yolo/coco8_clean/fine_tuned_model/val2/predictions.json...\n",
      "Results saved to \u001b[1m/home/tom/Desktop/Programming/Shared/Weird-Stuff-In-Traffic/Results/Segmentation-Detection/yolo/coco8_clean/fine_tuned_model/val2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "metrics = model.val(save_json=True, project= complete_validation_results_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
