{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "864d8f83",
   "metadata": {},
   "source": [
    "## Yolov11 Training Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f521bbb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4819bf",
   "metadata": {},
   "source": [
    "#### Key Sections\n",
    "\n",
    "1. [Training Setup](#training-setup)\n",
    "2. [Training](#training)\n",
    "3. [Hyperparameter Tuning](#hyperparameter-tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b89872e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6566ea4d",
   "metadata": {},
   "source": [
    "### Training Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1e2f1d-5f6c-4711-9277-36d23c31ba79",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a79b03-8ce8-48bf-8cb0-2b140aaff527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import re\n",
    "import cv2\n",
    "import random\n",
    "import shutil\n",
    "import torch\n",
    "import warnings\n",
    "import torchvision\n",
    "from datetime import datetime\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b64051c",
   "metadata": {},
   "source": [
    "##### Package Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1728d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.7.0.dev20250127+rocm6.3\n",
      "Torchvision version: 0.22.0.dev20250128+rocm6.3\n",
      "Is torch available? True\n"
     ]
    }
   ],
   "source": [
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"Torchvision version:\", torchvision.__version__)\n",
    "print(\"Is torch available?\",torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1338bd3",
   "metadata": {},
   "source": [
    "### Disable Warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8a30071-ccfa-478c-9dc9-75687d0c622e",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61761e99-7063-4248-995f-3cb194ef0053",
   "metadata": {},
   "source": [
    "### Setting Training Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6238489d-895d-4420-9e2a-7773740b0026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU _CudaDeviceProperties(name='AMD Radeon RX 7800 XT', major=11, minor=0, gcnArchName='gfx1101', total_memory=16368MB, multi_processor_count=30, uuid=38336232-6265-3432-3662-306564613532, L2_cache_size=4MB)\n",
      "# of CUDA devices available: 1\n"
     ]
    }
   ],
   "source": [
    "# Defining Device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Printing Necessary CUDA Info\n",
    "if str(device) == \"cuda\":\n",
    "    print(f\"Using GPU {torch.cuda.get_device_properties(device)}\")\n",
    "    print(\"# of CUDA devices available:\", torch.cuda.device_count())\n",
    "else:\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3ce8d6-12a0-468f-873c-e7aec1f8ca2d",
   "metadata": {},
   "source": [
    "### Emptying the GPU Cache (if necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "904136e3-472c-4e2f-9ed5-cb2e67036b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of free memory: 78.49\n"
     ]
    }
   ],
   "source": [
    "# Cleaning out the device cache\n",
    "def empty_cache() -> None:\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Displaying the free memory\n",
    "def print_free_memory():\n",
    "    free, total = torch.cuda.mem_get_info(device)\n",
    "    print(f\"Percent of free memory: {round(free/total *100,2)}\")\n",
    "\n",
    "# Running GPU info related functions\n",
    "empty_cache()\n",
    "print_free_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8cb24f-246b-4477-ab75-e0064547813b",
   "metadata": {},
   "source": [
    "### Memory Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9286844f-e298-456a-ad8f-01e36e1a1d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Memory Summary Function\n",
    "def memory_summary() -> None:\n",
    "    print(torch.cuda.memory_summary())\n",
    "\n",
    "# Running memory summary funciton\n",
    "memory_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29286d1-e71c-4d33-805f-9ed13c9aee04",
   "metadata": {},
   "source": [
    "### Preparing GPU (if necessary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0c87272-2af4-4a5f-bc22-14007272497a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU AMD Radeon RX 7800 XT is now setup\n"
     ]
    }
   ],
   "source": [
    "# For AMD GPU - 7800xt\n",
    "device_name = torch.cuda.get_device_name(0)\n",
    "if \"AMD\" in device_name or \"Radeon\" in device_name:\n",
    "    os.environ[\"HSA_OVERRIDE_GFX_VERSION\"] = \"11.0.0\"\n",
    "\n",
    "print(f\"GPU {torch.cuda.get_device_properties(device).name} is now setup\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8921cbf-9358-406c-992f-76262dc7b413",
   "metadata": {},
   "source": [
    "##### Local Setting Paths for Data, Base Model, and Output Directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9676daf4-f4f2-48ad-bf77-b3d4c76d39ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory Paths\n",
    "training_dataset_name = \"coco8\" # Change this once we have the necessary data\n",
    "yaml_training_dataset_name = \"coco8.yaml\" # Change this once we have the necessary data\n",
    "\n",
    "# Flexible Data Paths (needed for THI server)\n",
    "current_directory = os.getcwd()\n",
    "path_to_base_directory = re.search(rf\"(.*?){\"Weird-Stuff-In-Traffic\"}\", current_directory).group(1)\n",
    "training_yaml_data_path = f\"Weird-Stuff-In-Traffic/Data/yolo/{training_dataset_name}/{yaml_training_dataset_name}\"\n",
    "complete_training_data_path = path_to_base_directory + training_yaml_data_path\n",
    "\n",
    "# Model Paths\n",
    "model_name = \"yolo11n.pt\"\n",
    "simple_model_name = model_name.split(\".\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7916e1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974e00dd",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ead4800-4ba7-4b8a-8634-640d7ec273c1",
   "metadata": {},
   "source": [
    "##### Training - Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa901b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Model\n",
    "model = YOLO(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d409887e",
   "metadata": {},
   "source": [
    "##### Training - Training Configuration and Output Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75017570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training Configurations\n",
    "epochs = 3\n",
    "image_size = 640\n",
    "batch_size = 64\n",
    "\n",
    "# Output Folder Name\n",
    "output_folder_name = f'{datetime.now().strftime(\"%Y-%m-%d_%H-%M\")}_{simple_model_name}_{training_dataset_name}_{image_size}cuts_{epochs}epoch'\n",
    "\n",
    "# Model Storage and Results Path\n",
    "training_results_path = f\"Weird-Stuff-In-Traffic/Models/Segmentation-Detection/yolo/\"\n",
    "complete_training_results_path = path_to_base_directory + training_results_path + output_folder_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b72baab-579f-430f-822b-e6c936a69edb",
   "metadata": {},
   "source": [
    "##### Training - Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5adc8286-9462-4dcf-84d8-5ed6e43eabb8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5adc8286-9462-4dcf-84d8-5ed6e43eabb8",
    "outputId": "12d6b275-9b5c-43a7-adc7-d67fe06df401",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model Training Parameters\n",
    "training_params = {\n",
    "    'data': complete_training_data_path, # Local Dataset\n",
    "    'imgsz': image_size, #1024\n",
    "    'epochs': epochs,\n",
    "    'batch': batch_size,\n",
    "    'patience': 20,\n",
    "    'cos_lr': True,\n",
    "    #'rect': True,\n",
    "    'augment': True,\n",
    "    #'hsv_s': 0.45,\n",
    "    #'hsv_v': 0.3,\n",
    "    #'auto_augment': 'autoaugment',\n",
    "    'save': True,\n",
    "    'project': complete_training_results_path, # Local Save Directory\n",
    "    'name':  output_folder_name # Output Folder Name\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a127c6",
   "metadata": {},
   "source": [
    "##### Training - Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f622dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.114 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.103 ðŸš€ Python-3.12.3 torch-2.7.0.dev20250127+rocm6.3 CUDA:0 (AMD Radeon RX 7800 XT, 16368MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=/home/tom/Desktop/Programming/Shared/Weird-Stuff-In-Traffic/Data/yolo/test_set_chunk3/chunk3.yaml, epochs=1, time=None, patience=20, batch=64, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=/home/tom/Desktop/Programming/Shared/Weird-Stuff-In-Traffic/Model/Segmentation-Detection/yolo/2025-04-23_13-11_yolo11n_test_set_chunk3_640cuts_1epoch, name=2025-04-23_13-11_yolo11n_test_set_chunk3_640cuts_1epoch2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=True, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/home/tom/Desktop/Programming/Shared/Weird-Stuff-In-Traffic/Model/Segmentation-Detection/yolo/2025-04-23_13-11_yolo11n_test_set_chunk3_640cuts_1epoch/2025-04-23_13-11_yolo11n_test_set_chunk3_640cuts_1epoch2\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    430867  ultralytics.nn.modules.head.Detect           [1, [64, 128, 256]]           \n",
      "YOLO11n summary: 181 layers, 2,590,035 parameters, 2,590,019 gradients, 6.4 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /home/tom/Desktop/Programming/Shared/Weird-Stuff-In-Traffic/Data/yolo/test_set_chunk3/labels/train... 142 images, 2 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 144/144 [00:00<00:00, 4954.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /home/tom/Desktop/Programming/Shared/Weird-Stuff-In-Traffic/Data/yolo/test_set_chunk3/labels/train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /home/tom/Desktop/Programming/Shared/Weird-Stuff-In-Traffic/Data/yolo/test_set_chunk3/labels/val... 32 images, 1 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:00<00:00, 2554.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /home/tom/Desktop/Programming/Shared/Weird-Stuff-In-Traffic/Data/yolo/test_set_chunk3/labels/val.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to /home/tom/Desktop/Programming/Shared/Weird-Stuff-In-Traffic/Model/Segmentation-Detection/yolo/2025-04-23_13-11_yolo11n_test_set_chunk3_640cuts_1epoch/2025-04-23_13-11_yolo11n_test_set_chunk3_640cuts_1epoch2/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1m/home/tom/Desktop/Programming/Shared/Weird-Stuff-In-Traffic/Model/Segmentation-Detection/yolo/2025-04-23_13-11_yolo11n_test_set_chunk3_640cuts_1epoch/2025-04-23_13-11_yolo11n_test_set_chunk3_640cuts_1epoch2\u001b[0m\n",
      "Starting training for 1 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/1     0.254G      1.829      4.367      1.143         35        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [02:17<00:00, 45.71s/it] \n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:10<00:00, 10.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         37    0.00131      0.351     0.0027   0.000918\n",
      "\n",
      "1 epochs completed in 0.041 hours.\n",
      "Optimizer stripped from /home/tom/Desktop/Programming/Shared/Weird-Stuff-In-Traffic/Model/Segmentation-Detection/yolo/2025-04-23_13-11_yolo11n_test_set_chunk3_640cuts_1epoch/2025-04-23_13-11_yolo11n_test_set_chunk3_640cuts_1epoch2/weights/last.pt, 5.5MB\n",
      "Optimizer stripped from /home/tom/Desktop/Programming/Shared/Weird-Stuff-In-Traffic/Model/Segmentation-Detection/yolo/2025-04-23_13-11_yolo11n_test_set_chunk3_640cuts_1epoch/2025-04-23_13-11_yolo11n_test_set_chunk3_640cuts_1epoch2/weights/best.pt, 5.5MB\n",
      "\n",
      "Validating /home/tom/Desktop/Programming/Shared/Weird-Stuff-In-Traffic/Model/Segmentation-Detection/yolo/2025-04-23_13-11_yolo11n_test_set_chunk3_640cuts_1epoch/2025-04-23_13-11_yolo11n_test_set_chunk3_640cuts_1epoch2/weights/best.pt...\n",
      "Ultralytics 8.3.103 ðŸš€ Python-3.12.3 torch-2.7.0.dev20250127+rocm6.3 CUDA:0 (AMD Radeon RX 7800 XT, 16368MiB)\n",
      "YOLO11n summary (fused): 100 layers, 2,582,347 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:13<00:00, 13.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         33         37    0.00141      0.378    0.00157   0.000528\n",
      "Speed: 0.1ms preprocess, 399.8ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Results saved to \u001b[1m/home/tom/Desktop/Programming/Shared/Weird-Stuff-In-Traffic/Model/Segmentation-Detection/yolo/2025-04-23_13-11_yolo11n_test_set_chunk3_640cuts_1epoch/2025-04-23_13-11_yolo11n_test_set_chunk3_640cuts_1epoch2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results = model.train(**training_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d8c36c",
   "metadata": {},
   "source": [
    "##### Training - Printing Key Training Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1fe826-eb72-4c70-9d8a-79ea10677342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Training completed. ### \n",
      "\n",
      " Key metrics:\n",
      "X (all classes): 0.0005\n",
      "mAP50 (all classes): 0.0016\n",
      "mAP50-95 (all classes)??: 0.0003\n",
      "\n",
      "Class-specific metrics:\n",
      "weird:\n",
      "  Precision: 0.0014\n",
      "  Recall: 0.3784\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# After training, print the most important metrics\n",
    "print(\"\\n### Training completed. ### \\n\\n Key metrics:\")\n",
    "print(f\"X (all classes): {results.box.map:.4f}\")  #??\n",
    "print(f\"mAP50 (all classes): {results.box.map50:.4f}\")\n",
    "print(f\"mAP50-95 (all classes)??: {results.box.map75:.4f}\")  # This might be mAP50-95??\n",
    "#print(f\"Precision: {results.box.p:.4f}\")\n",
    "#print(f\"Recall: {results.box.r:.4f}\")\n",
    "\n",
    "# Print class-specific metrics if available\n",
    "if hasattr(results, 'names'):\n",
    "    print(\"\\nClass-specific metrics:\")\n",
    "    for i, class_name in results.names.items():\n",
    "        print(f\"{class_name}:\")\n",
    "        print(f\"  Precision: {results.box.p[i]:.4f}\")\n",
    "        print(f\"  Recall: {results.box.r[i]:.4f}\") \n",
    "        #print(f\"  mAP50: {results.box.map50[i]:.4f}\") # This breaks the code, revisit later\n",
    "        #print(f\"  mAP50-95: {results.box.map[i]:.4f}\") # This breaks the code, revisit later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f3efaa",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eq1Nx6KmdN9F",
   "metadata": {
    "id": "eq1Nx6KmdN9F"
   },
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe828c4-55c0-4775-93fe-9ac1cf8e0084",
   "metadata": {},
   "source": [
    "##### Builtin ray tune (Hyperband)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qcH8EVb0dNil",
   "metadata": {
    "id": "qcH8EVb0dNil"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-04-21 17:59:31</td></tr>\n",
       "<tr><td>Running for: </td><td>00:01:28.49        </td></tr>\n",
       "<tr><td>Memory:      </td><td>46.4/47.1 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 2.000: None<br>Logical resource usage: 24.0/24 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  : ***LOW MEMORY*** less than 10% of the memory on this node is available for use. This can cause unexpected crashes. Consider reducing the memory used by your application or reducing the Ray object store size by setting `object_store_memory` when calling `ray.init`.\n",
       "  \n",
       "  \n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name       </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">     bgr</th><th style=\"text-align: right;\">      box</th><th style=\"text-align: right;\">     cls</th><th style=\"text-align: right;\">  copy_paste</th><th style=\"text-align: right;\">  degrees</th><th style=\"text-align: right;\">  fliplr</th><th style=\"text-align: right;\">   flipud</th><th style=\"text-align: right;\">    hsv_h</th><th style=\"text-align: right;\">   hsv_s</th><th style=\"text-align: right;\">   hsv_v</th><th style=\"text-align: right;\">      lr0</th><th style=\"text-align: right;\">     lrf</th><th style=\"text-align: right;\">   mixup</th><th style=\"text-align: right;\">  momentum</th><th style=\"text-align: right;\">  mosaic</th><th style=\"text-align: right;\">  perspective</th><th style=\"text-align: right;\">   scale</th><th style=\"text-align: right;\">  shear</th><th style=\"text-align: right;\">  translate</th><th style=\"text-align: right;\">  warmup_epochs</th><th style=\"text-align: right;\">  warmup_momentum</th><th style=\"text-align: right;\">  weight_decay</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>_tune_682f6_00000</td><td>RUNNING </td><td>127.0.0.1:26916</td><td style=\"text-align: right;\">0.807998</td><td style=\"text-align: right;\">0.0590594</td><td style=\"text-align: right;\">2.75534 </td><td style=\"text-align: right;\">    0.839546</td><td style=\"text-align: right;\">  10.8361</td><td style=\"text-align: right;\">0.309897</td><td style=\"text-align: right;\">0.0209788</td><td style=\"text-align: right;\">0.0686011</td><td style=\"text-align: right;\">0.146443</td><td style=\"text-align: right;\">0.845052</td><td style=\"text-align: right;\">0.086305 </td><td style=\"text-align: right;\">0.535429</td><td style=\"text-align: right;\">0.115195</td><td style=\"text-align: right;\">  0.603867</td><td style=\"text-align: right;\">0.285679</td><td style=\"text-align: right;\">  0.000450814</td><td style=\"text-align: right;\">0.469152</td><td style=\"text-align: right;\">5.92209</td><td style=\"text-align: right;\">   0.698329</td><td style=\"text-align: right;\">       0.370264</td><td style=\"text-align: right;\">        0.668647 </td><td style=\"text-align: right;\">   0.000527649</td></tr>\n",
       "<tr><td>_tune_682f6_00001</td><td>RUNNING </td><td>127.0.0.1:27636</td><td style=\"text-align: right;\">0.548319</td><td style=\"text-align: right;\">0.0974355</td><td style=\"text-align: right;\">0.449079</td><td style=\"text-align: right;\">    0.813496</td><td style=\"text-align: right;\">  35.1314</td><td style=\"text-align: right;\">0.589772</td><td style=\"text-align: right;\">0.893483 </td><td style=\"text-align: right;\">0.063297 </td><td style=\"text-align: right;\">0.76401 </td><td style=\"text-align: right;\">0.348532</td><td style=\"text-align: right;\">0.0163547</td><td style=\"text-align: right;\">0.812503</td><td style=\"text-align: right;\">0.448122</td><td style=\"text-align: right;\">  0.736004</td><td style=\"text-align: right;\">0.550122</td><td style=\"text-align: right;\">  0.000480043</td><td style=\"text-align: right;\">0.061851</td><td style=\"text-align: right;\">2.89273</td><td style=\"text-align: right;\">   0.514574</td><td style=\"text-align: right;\">       0.741771</td><td style=\"text-align: right;\">        0.0959942</td><td style=\"text-align: right;\">   0.000782802</td></tr>\n",
       "<tr><td>_tune_682f6_00002</td><td>RUNNING </td><td>127.0.0.1:27132</td><td style=\"text-align: right;\">0.495834</td><td style=\"text-align: right;\">0.0381565</td><td style=\"text-align: right;\">3.39269 </td><td style=\"text-align: right;\">    0.522161</td><td style=\"text-align: right;\">  23.5552</td><td style=\"text-align: right;\">0.680139</td><td style=\"text-align: right;\">0.136561 </td><td style=\"text-align: right;\">0.0835087</td><td style=\"text-align: right;\">0.41526 </td><td style=\"text-align: right;\">0.603452</td><td style=\"text-align: right;\">0.0556526</td><td style=\"text-align: right;\">0.670238</td><td style=\"text-align: right;\">0.294094</td><td style=\"text-align: right;\">  0.674271</td><td style=\"text-align: right;\">0.58838 </td><td style=\"text-align: right;\">  0.000239809</td><td style=\"text-align: right;\">0.797217</td><td style=\"text-align: right;\">9.50009</td><td style=\"text-align: right;\">   0.181095</td><td style=\"text-align: right;\">       2.43964 </td><td style=\"text-align: right;\">        0.0498073</td><td style=\"text-align: right;\">   0.000635946</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_tune pid=26916)\u001b[0m New https://pypi.org/project/ultralytics/8.3.112 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\n",
      "\u001b[36m(_tune pid=26916)\u001b[0m Ultralytics 8.3.111 ðŸš€ Python-3.12.10 torch-2.6.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4070 SUPER, 12282MiB)\n",
      "\u001b[36m(_tune pid=26916)\u001b[0m \u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=C:\\Users\\Adminero\\Documents\\Valomalo\\final dataset_nobackground\\cutouts1024\\data.yaml, epochs=2, time=None, patience=100, batch=24, imgsz=1024, save=True, save_period=-1, cache=False, device=cuda:0, workers=8, project=C:\\Users\\Adminero\\Documents\\Valomalo\\Saved Runs, name=train14, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.0863049779114844, lrf=0.5354291282339889, momentum=0.6038670880887619, weight_decay=0.0005276491786742285, warmup_epochs=0.37026370736000236, warmup_momentum=0.6686474218983107, warmup_bias_lr=0.1, box=0.05905939322810157, cls=2.755336571812989, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.06860105158873829, hsv_s=0.1464425815693808, hsv_v=0.845051754937401, degrees=10.83606978582979, translate=0.6983290139797507, scale=0.46915198452178897, shear=5.922093048681276, perspective=0.0004508142143830468, flipud=0.020978808172154806, fliplr=0.30989691449366497, bgr=0.807997912340066, mosaic=0.2856790704856571, mixup=0.1151949953304856, copy_paste=0.8395459782129402, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=C:\\Users\\Adminero\\Documents\\Valomalo\\Saved Runs\\train14\n",
      "\u001b[36m(_tune pid=26916)\u001b[0m Overriding model.yaml nc=80 with nc=2\n",
      "\u001b[36m(_tune pid=26916)\u001b[0m \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m                    from  n    params  module                                       arguments                     \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m   0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m   1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m   2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m   3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m   4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m   5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m   6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m   7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m   8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m   9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m  10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m  11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m  12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m  13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m  14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m  15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m  16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m  17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m  18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m  19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m  20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m  21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m  22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m  23        [16, 19, 22]  1    431062  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
      "\u001b[36m(_tune pid=27636)\u001b[0m New https://pypi.org/project/ultralytics/8.3.112 available ðŸ˜ƒ Update with 'pip install -U ultralytics'\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(_tune pid=27636)\u001b[0m Ultralytics 8.3.111 ðŸš€ Python-3.12.10 torch-2.6.0+cu126 CUDA:0 (NVIDIA GeForce RTX 4070 SUPER, 12282MiB)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_tune pid=27636)\u001b[0m \u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolo11n.pt, data=C:\\Users\\Adminero\\Documents\\Valomalo\\final dataset_nobackground\\cutouts1024\\data.yaml, epochs=2, time=None, patience=100, batch=24, imgsz=1024, save=True, save_period=-1, cache=False, device=cuda:0, workers=8, project=C:\\Users\\Adminero\\Documents\\Valomalo\\Saved Runs, name=train13, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.016354728253908123, lrf=0.8125030881519932, momentum=0.7360041068128451, weight_decay=0.0007828015959548872, warmup_epochs=0.7417712491280043, warmup_momentum=0.09599422311649486, warmup_bias_lr=0.1, box=0.09743548757090052, cls=0.4490786386453679, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.0632970079441245, hsv_s=0.7640102450197103, hsv_v=0.3485320607537194, degrees=35.13138749264468, translate=0.5145741097303617, scale=0.06185097013770369, shear=2.892730120150059, perspective=0.00048004270278436756, flipud=0.8934826214385398, fliplr=0.5897721849540926, bgr=0.5483192794648384, mosaic=0.5501217402686963, mixup=0.4481224083319094, copy_paste=0.8134964089810688, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=C:\\Users\\Adminero\\Documents\\Valomalo\\Saved Runs\\train13\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_tune pid=27132)\u001b[0m \n",
      "\u001b[36m(_tune pid=27132)\u001b[0m  10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      "\u001b[36m(_tune pid=27636)\u001b[0m \n",
      "\u001b[36m(_tune pid=27636)\u001b[0m  10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m YOLO11n summary: 181 layers, 2,590,230 parameters, 2,590,214 gradients, 6.4 GFLOPs\n",
      "\u001b[36m(_tune pid=26916)\u001b[0m \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m Transferred 448/499 items from pretrained weights\n",
      "\u001b[36m(_tune pid=27132)\u001b[0m \n",
      "\u001b[36m(_tune pid=27636)\u001b[0m \n",
      "\u001b[36m(_tune pid=26916)\u001b[0m Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[36m(_tune pid=26916)\u001b[0m \u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[36m(_tune pid=26916)\u001b[0m Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0.00/5.35M [00:00<?, ?B/s]\n",
      "  7%|â–‹         | 384k/5.35M [00:00<00:01, 3.10MB/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.35M/5.35M [00:01<00:00, 5.14MB/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.35M/5.35M [00:01<00:00, 4.95MB/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.35M/5.35M [00:01<00:00, 3.18MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_tune pid=26916)\u001b[0m \u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Adminero\\Documents\\Valomalo\\final dataset_nobackground\\cutouts1024\\train\\labels.cache... 2471 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2471/2471 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_tune pid=26916)\u001b[0m \u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 385.3Â±55.1 MB/s, size: 173.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0.00/5.35M [00:00<?, ?B/s]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 4.50M/5.35M [00:01<00:00, 4.48MB/s]\u001b[32m [repeated 27x across cluster]\u001b[0m\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Adminero\\Documents\\Valomalo\\final dataset_nobackground\\cutouts1024\\val\\labels.cache... 308 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 308/308 [00:00<?, ?it/s]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_tune pid=27636)\u001b[0m Overriding model.yaml nc=80 with nc=2\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_tune pid=27636)\u001b[0m                    from  n    params  module                                       arguments                     \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_tune pid=27636)\u001b[0m  20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[36m(_tune pid=27636)\u001b[0m   4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_tune pid=27636)\u001b[0m  22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_tune pid=27636)\u001b[0m   9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_tune pid=27636)\u001b[0m  14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(_tune pid=27636)\u001b[0m  21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_tune pid=27636)\u001b[0m  19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(_tune pid=27636)\u001b[0m  23        [16, 19, 22]  1    431062  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_tune pid=27636)\u001b[0m YOLO11n summary: 181 layers, 2,590,230 parameters, 2,590,214 gradients, 6.4 GFLOPs\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_tune pid=27636)\u001b[0m Transferred 448/499 items from pretrained weights\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_tune pid=27636)\u001b[0m Freezing layer 'model.23.dfl.conv.weight'\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_tune pid=27636)\u001b[0m \u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_tune pid=27636)\u001b[0m Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_tune pid=27636)\u001b[0m \u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_tune pid=26916)\u001b[0m \u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1212.9Â±378.7 MB/s, size: 177.3 KB)\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(_tune pid=26916)\u001b[0m Plotting labels to C:\\Users\\Adminero\\Documents\\Valomalo\\Saved Runs\\train14\\labels.jpg... \n",
      "\u001b[36m(_tune pid=27636)\u001b[0m \u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 317.2Â±97.7 MB/s, size: 177.3 KB)\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-21 17:59:31,882\tWARNING tune.py:219 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2025-04-21 17:59:31,886\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to 'C:/Users/Adminero/Documents/Valomalo/Saved Runs/tune_exp_18' in 0.0033s.\n",
      "  0%|          | 0/103 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Adminero\\Documents\\Valomalo\\final dataset_nobackground\\cutouts1024\\val\\labels.cache... 308 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 308/308 [00:00<?, ?it/s]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(_tune pid=27636)\u001b[0m \u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.016354728253908123' and 'momentum=0.7360041068128451' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[36m(_tune pid=27636)\u001b[0m \u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0008806517954492481), 87 bias(decay=0.0)\n",
      "\u001b[36m(_tune pid=27636)\u001b[0m Image sizes 1024 train, 1024 val\n",
      "\u001b[36m(_tune pid=27636)\u001b[0m Using 8 dataloader workers\n",
      "\u001b[36m(_tune pid=27636)\u001b[0m Logging results to \u001b[1mC:\\Users\\Adminero\\Documents\\Valomalo\\Saved Runs\\train13\u001b[0m\n",
      "\u001b[36m(_tune pid=27636)\u001b[0m Starting training for 2 epochs...\n",
      "\u001b[36m(_tune pid=27636)\u001b[0m \n",
      "\u001b[36m(_tune pid=27636)\u001b[0m       Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[36m(_tune pid=27132)\u001b[0m Plotting labels to C:\\Users\\Adminero\\Documents\\Valomalo\\Saved Runs\\train14\\labels.jpg... \u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(_tune pid=27132)\u001b[0m \n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "from ultralytics import YOLO\n",
    "from ray import tune\n",
    "\n",
    "model_name = \"yolo11n.pt\"\n",
    "model = YOLO(model_name)\n",
    "hypp_space = {}\n",
    "\n",
    "result_grid = model.tune(\n",
    "    device='cuda:0',\n",
    "    data=dataset_path,\n",
    "    iterations=3,\n",
    "    grace_period = 2,\n",
    "    name=\"tune_exp_1\", \n",
    "    #space = hypp_space,\n",
    "    #resume=True,\n",
    "    imgsz=1024,\n",
    "    epochs=2,\n",
    "    batch=24,\n",
    "    project=save_dir,\n",
    "    use_ray=True)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2602ff-9923-412c-bc5a-17ee679a8d8f",
   "metadata": {},
   "source": [
    "##### Builtin YOLO tune (genetic algorithm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab59344c-0e4d-4c4f-8e68-583ba08a8aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model_name = \"yolo11n.pt\"\n",
    "model = YOLO(model_name)\n",
    "hypp_space = {}\n",
    "\n",
    "model.tune(\n",
    "    device='cuda:0',\n",
    "    data=dataset_path,\n",
    "    epochs=30,\n",
    "    name=\"tune_exp_1\", \n",
    "    imgsz=1024,\n",
    "    batch=24,\n",
    "    iterations=300,\n",
    "    optimizer=\"AdamW\",\n",
    "    plots=True,\n",
    "    save=False,\n",
    "    val=False,\n",
    ")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051e339d-fc40-4e2f-afb4-71359cac4166",
   "metadata": {},
   "source": [
    "##### Custom Optuna trial (Bayesian optimization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9125d3c2-1b3a-484b-96ca-568eac174646",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import optuna\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparameters to optimize\n",
    "    lr = trial.suggest_float('lr0', 1e-5, 1e-2, log=True)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 0.0001, 0.01)\n",
    "    dropout = trial.suggest_float('dropout', 0.0, 0.5)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [8, 16, 32, 64])\n",
    "    \n",
    "    # Initialize YOLO model\n",
    "    model = YOLO('yolov8n.yaml')  \n",
    "    \n",
    "    # Train with suggested hyperparameters\n",
    "    results = model.train(\n",
    "        data='coco128.yaml',\n",
    "        epochs=50,\n",
    "        batch=batch_size,\n",
    "        lr0=lr,\n",
    "        weight_decay=weight_decay,\n",
    "        dropout=dropout,\n",
    "        verbose=False  # Reduce output clutter\n",
    "    )\n",
    "    \n",
    "    # Return the metric to optimize \n",
    "    return results.results_dict['metrics/mAP50-95(B)']\n",
    "\n",
    "# Create study and optimize\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Print best results\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "print(f'  Value: {trial.value}')\n",
    "print('  Params: ')\n",
    "for key, value in trial.params.items():\n",
    "    print(f'    {key}: {value}')\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
